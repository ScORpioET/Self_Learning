{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2c4196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from config.ipynb\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import import_ipynb\n",
    "from config import DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd98f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # layer1(conv)\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels//4, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels//4)\n",
    "        # layer2(upconv)\n",
    "        self.upconv = nn.ConvTranspose2d(\n",
    "            in_channels//4, in_channels//4, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(in_channels//4)\n",
    "        # layer3(conv)\n",
    "        self.conv2 = nn.Conv2d(in_channels//4, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        x = self.relu(self.bn1(self.conv1(image)))\n",
    "        x = self.relu(self.bn2(self.upconv(x)))\n",
    "        x = self.relu(self.bn3(self.conv2(x)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805fc7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # base on Resnet-18\n",
    "        base = resnet18(pretrained=True)\n",
    "\n",
    "        self.firstconv = nn.Sequential(\n",
    "            base.conv1,\n",
    "            base.bn1,\n",
    "            base.relu,\n",
    "            base.maxpool,\n",
    "        )\n",
    "        \n",
    "        self.encoder1 = base.layer1\n",
    "        self.encoder2 = base.layer2\n",
    "        self.encoder3 = base.layer3\n",
    "        self.encoder4 = base.layer4\n",
    "\n",
    "        self.center = Decoder(512, 512)\n",
    "\n",
    "        self.decoder1 = Decoder(512, 256)\n",
    "        self.decoder2 = Decoder(256, 128)\n",
    "        self.decoder3 = Decoder(128, 64)\n",
    "        self.decoder4 = Decoder(64, 64)\n",
    "        \n",
    "        self.finalconv = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.1, False),\n",
    "            nn.Conv2d(32, num_classes, kernel_size=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, image, extract_feature=False):\n",
    "        x = self.firstconv(image)\n",
    "        x = self.encoder1(x)\n",
    "        x = self.encoder2(x)\n",
    "        x = self.encoder3(x)\n",
    "        x = self.encoder4(x)\n",
    "        \n",
    "        # return壓縮圖片\n",
    "        if(extract_feature):\n",
    "            return x \n",
    "        \n",
    "        x = self.center(x)\n",
    "        x = self.decoder1(x)\n",
    "        x = self.decoder2(x)\n",
    "        x = self.decoder3(x)\n",
    "        x = self.decoder4(x)\n",
    "        \n",
    "        output = self.finalconv(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f1afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 128, 128])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "           Conv2d-67            [-1, 128, 7, 7]         589,824\n",
      "      BatchNorm2d-68            [-1, 128, 7, 7]             256\n",
      "             ReLU-69            [-1, 128, 7, 7]               0\n",
      "  ConvTranspose2d-70          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-71          [-1, 128, 14, 14]             256\n",
      "             ReLU-72          [-1, 128, 14, 14]               0\n",
      "           Conv2d-73          [-1, 512, 14, 14]         589,824\n",
      "      BatchNorm2d-74          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-75          [-1, 512, 14, 14]               0\n",
      "          Decoder-76          [-1, 512, 14, 14]               0\n",
      "           Conv2d-77          [-1, 128, 14, 14]         589,824\n",
      "      BatchNorm2d-78          [-1, 128, 14, 14]             256\n",
      "             ReLU-79          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-80          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-81          [-1, 128, 28, 28]             256\n",
      "             ReLU-82          [-1, 128, 28, 28]               0\n",
      "           Conv2d-83          [-1, 256, 28, 28]         294,912\n",
      "      BatchNorm2d-84          [-1, 256, 28, 28]             512\n",
      "             ReLU-85          [-1, 256, 28, 28]               0\n",
      "          Decoder-86          [-1, 256, 28, 28]               0\n",
      "           Conv2d-87           [-1, 64, 28, 28]         147,456\n",
      "      BatchNorm2d-88           [-1, 64, 28, 28]             128\n",
      "             ReLU-89           [-1, 64, 28, 28]               0\n",
      "  ConvTranspose2d-90           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-91           [-1, 64, 56, 56]             128\n",
      "             ReLU-92           [-1, 64, 56, 56]               0\n",
      "           Conv2d-93          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-94          [-1, 128, 56, 56]             256\n",
      "             ReLU-95          [-1, 128, 56, 56]               0\n",
      "          Decoder-96          [-1, 128, 56, 56]               0\n",
      "           Conv2d-97           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-98           [-1, 32, 56, 56]              64\n",
      "             ReLU-99           [-1, 32, 56, 56]               0\n",
      " ConvTranspose2d-100         [-1, 32, 112, 112]           9,216\n",
      "     BatchNorm2d-101         [-1, 32, 112, 112]              64\n",
      "            ReLU-102         [-1, 32, 112, 112]               0\n",
      "          Conv2d-103         [-1, 64, 112, 112]          18,432\n",
      "     BatchNorm2d-104         [-1, 64, 112, 112]             128\n",
      "            ReLU-105         [-1, 64, 112, 112]               0\n",
      "         Decoder-106         [-1, 64, 112, 112]               0\n",
      "          Conv2d-107         [-1, 16, 112, 112]           9,216\n",
      "     BatchNorm2d-108         [-1, 16, 112, 112]              32\n",
      "            ReLU-109         [-1, 16, 112, 112]               0\n",
      " ConvTranspose2d-110         [-1, 16, 224, 224]           2,304\n",
      "     BatchNorm2d-111         [-1, 16, 224, 224]              32\n",
      "            ReLU-112         [-1, 16, 224, 224]               0\n",
      "          Conv2d-113         [-1, 64, 224, 224]           9,216\n",
      "     BatchNorm2d-114         [-1, 64, 224, 224]             128\n",
      "            ReLU-115         [-1, 64, 224, 224]               0\n",
      "         Decoder-116         [-1, 64, 224, 224]               0\n",
      "          Conv2d-117         [-1, 32, 224, 224]          18,432\n",
      "     BatchNorm2d-118         [-1, 32, 224, 224]              64\n",
      "            ReLU-119         [-1, 32, 224, 224]               0\n",
      "       Dropout2d-120         [-1, 32, 224, 224]               0\n",
      "          Conv2d-121          [-1, 1, 224, 224]              33\n",
      "================================================================\n",
      "Total params: 13,901,153\n",
      "Trainable params: 13,901,153\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 299.89\n",
      "Params size (MB): 53.03\n",
      "Estimated Total Size (MB): 353.49\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from torchsummary import summary\n",
    "    \n",
    "    inp = torch.ones((1, 3, 128, 128)).to(DEVICE)\n",
    "    net = AutoEncoder().to(DEVICE)\n",
    "    out = net(inp)\n",
    "    print(out.shape)\n",
    "    summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a5b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
